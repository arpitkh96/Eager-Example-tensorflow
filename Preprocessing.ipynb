{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load weights\n",
    "inception = InceptionResNetV2(weights='imagenet', include_top=True)\n",
    "inception.graph = tf.get_default_graph()\n",
    "print(inception.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inception.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with inception.graph.as_default():\n",
    "        get_3rd_layer_output = K.function([inception.layers[0].input],\n",
    "                                  [inception.layers[-2].output])\n",
    "        embed=get_3rd_layer_output([grayscaled_rgb_resized])[0]\n",
    "        #embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"Test/\"\n",
    "folders=os.listdir(train_path)\n",
    "files=[train_path+each for each in folders]\n",
    "def generate():\n",
    "    i=0\n",
    "    for batch in range(0,len(files),150):\n",
    "        images=[]\n",
    "        paths=[]\n",
    "        print(batch)\n",
    "        for f in files[batch:batch+150]:\n",
    "            paths.append(f)\n",
    "            images.append(img_to_array(load_img(f)))\n",
    "        X = np.array(images, dtype=float)\n",
    "        yield (paths,X)\n",
    "    \n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n",
      "1800\n",
      "1950\n",
      "2100\n",
      "2250\n",
      "2400\n",
      "2550\n",
      "2700\n",
      "2850\n",
      "3000\n",
      "3150\n",
      "3300\n",
      "3450\n",
      "3600\n",
      "3750\n",
      "3900\n",
      "4050\n",
      "4200\n",
      "4350\n",
      "4500\n",
      "4650\n",
      "4800\n",
      "4950\n",
      "5100\n",
      "5250\n",
      "5400\n",
      "5550\n",
      "5700\n",
      "5850\n",
      "6000\n",
      "6150\n",
      "6300\n",
      "6450\n",
      "6600\n",
      "6750\n",
      "6900\n",
      "7050\n",
      "7200\n",
      "7350\n",
      "7500\n",
      "7650\n",
      "7800\n",
      "7950\n",
      "8100\n",
      "8250\n",
      "8400\n",
      "8550\n",
      "8700\n",
      "8850\n",
      "9000\n",
      "9150\n",
      "9300\n",
      "9450\n",
      "9600\n",
      "9750\n",
      "9900\n",
      "10050\n",
      "10200\n",
      "10350\n",
      "10500\n",
      "10650\n",
      "10800\n",
      "10950\n",
      "11100\n",
      "11250\n",
      "11400\n",
      "11550\n"
     ]
    }
   ],
   "source": [
    "t=generate()\n",
    "names=[]\n",
    "embeddings=[]\n",
    "index=0\n",
    "for i,j in t:\n",
    "    grayscaled_rgb = gray2rgb(rgb2gray(j))\n",
    "    embed=create_inception_embedding(grayscaled_rgb)\n",
    "    names.extend(i)\n",
    "    embeddings.extend(embed)\n",
    "    index+=1\n",
    "    if(len(embeddings)!=len(names)):\n",
    "        break\n",
    "\n",
    "np.save(\"testtest\",embeddings)\n",
    "np.save('testtest1',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = open('names.txt', 'w')\n",
    "\n",
    "\n",
    "for item in names:\n",
    "    thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    if f not in names:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11572, 1000)\n"
     ]
    }
   ],
   "source": [
    "t=np.load('test.npy')\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test\",embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11100\n",
      "11250\n",
      "11400\n",
      "11550\n"
     ]
    }
   ],
   "source": [
    "for batch in range(0,len(files),150):\n",
    "    if batch>11000:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files[11550:11550+150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d2de9ab64e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbyt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbiglist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    471\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    472\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2555\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_path=\"Train/\"\n",
    "folders=os.listdir(train_path)\n",
    "files=[]\n",
    "for f in folders:\n",
    "    files.extend([train_path+f+\"/\"+each for each in os.listdir(train_path+f)])\n",
    "byt=0\n",
    "biglist=[]\n",
    "for f in files:\n",
    "    byt+=os.path.getsize(f)\n",
    "    biglist.append(img_to_array(load_img(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541.6060152053833\n"
     ]
    }
   ],
   "source": [
    "print(byt/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

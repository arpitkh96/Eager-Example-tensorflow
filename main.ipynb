{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "#from keras import backend as K\n",
    "import timeit\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ColorModel, self).__init__()\n",
    "        self.layer1 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', strides=2)\n",
    "        self.layer2 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same')\n",
    "        self.layer3 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides=2)\n",
    "        self.layer4 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same')\n",
    "        self.layer5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides=2)\n",
    "        self.layer6 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same')\n",
    "        self.layer7 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same')\n",
    "        self.layer8 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same')\n",
    "        self.layer9 = tf.keras.layers.RepeatVector(32 * 32)\n",
    "        self.layer10 = tf.keras.layers.Reshape(([32, 32, 1536]))\n",
    "#        layer11 = concatenate([encoder_output, fusion_output], axis=3) \n",
    "        self.layer12 = tf.keras.layers.Conv2D(256, (1, 1), activation='relu', padding='same')\n",
    "\n",
    "        #Decoder\n",
    "        self.layer13 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same')\n",
    "        self.layer14 = tf.keras.layers.UpSampling2D((2, 2))\n",
    "        self.layer15 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same')\n",
    "        self.layer16 = tf.keras.layers.UpSampling2D((2, 2))\n",
    "        self.layer17 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same')\n",
    "        self.layer18 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same')\n",
    "        self.layer19 = tf.keras.layers.Conv2D(2, (3, 3), activation='tanh', padding='same')\n",
    "        self.layer20 = tf.keras.layers.UpSampling2D((2, 2))\n",
    "        \n",
    "    def call(self, input1,input2):\n",
    "        \"\"\"Run the model.\"\"\"\n",
    "        #Input 1 is greyscale image. Input 2 is imagenet embeddings for the image of size [1536,1]\n",
    "        result = self.layer1(input1)\n",
    "        result = self.layer2(result)\n",
    "        result = self.layer3(result)\n",
    "        result = self.layer4(result)\n",
    "        result = self.layer5(result)\n",
    "        result = self.layer6(result)\n",
    "        result = self.layer7(result)\n",
    "        result = self.layer8(result)\n",
    "        result1=self.layer9(input2)\n",
    "        result1=self.layer10(result1)\n",
    "        result=tf.keras.layers.concatenate([result,result1])\n",
    "\n",
    "        result = self.layer12(result)\n",
    "        result = self.layer13(result)\n",
    "        result = self.layer14(result)\n",
    "        result = self.layer15(result)\n",
    "        result = self.layer16(result)\n",
    "        result = self.layer17(result)\n",
    "        result = self.layer18(result)\n",
    "        result = self.layer19(result)\n",
    "        result = self.layer20(result)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ColorModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for nested folders\n",
    "train_path=\"Train/\"\n",
    "folders=os.listdir(train_path)\n",
    "files=[]\n",
    "for f in folders:\n",
    "    files.extend([train_path+f+\"/\"+each for each in os.listdir(train_path+f)])\n",
    "random.shuffle(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x,x1, y):\n",
    "    y_ = model(x,x1)\n",
    "    return tf.losses.mean_squared_error(labels=y, predictions=y_)\n",
    "\n",
    "\n",
    "def grad(model, inputs,embed, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs,embed, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved embeddings from imagenet . Generate these using preprocessing.ipynb\n",
    "embeddings=np.load(\"test.npy\")\n",
    "names=np.load('test1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_gen():\n",
    "    global files\n",
    "    i=0\n",
    "    while True:\n",
    "        if(i>len(files) or i+1>len(files)):\n",
    "            i=0\n",
    "        x,x1,y=read_images(files[i:i+1])\n",
    "        x=x[0]\n",
    "        x1=x1[0]\n",
    "        y=y[0]\n",
    "        i+=1\n",
    "        yield x,x1,y\n",
    "        \n",
    "def read_images(files):\n",
    "    X = []\n",
    "    embed = []\n",
    "    for filename in files:\n",
    "        X.append(img_to_array(load_img(filename)))\n",
    "        embed.append(embeddings[np.argwhere(names == filename)[0][0]])\n",
    "\n",
    "    embed = np.array(embed, dtype=float)\n",
    "    X = np.array(X, dtype=float)/255\n",
    "    grayscaled_rgb = gray2rgb(rgb2gray(X))\n",
    "    lab_batch = rgb2lab(X)\n",
    "    X_batch = lab_batch[:,:,:,0]\n",
    "    X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "    Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "    return (X_batch,embed, Y_batch)\n",
    "\n",
    "val_x,val_x1,val_y = read_images(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,i):\n",
    "    color_me = []\n",
    "    color_me.append(img_to_array(load_img(files[0])))\n",
    "    color_me = np.array(color_me, dtype=float)\n",
    "    gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
    "    color_me_embed =embeddings[np.argwhere(names == files[0])[0][0]]\n",
    "    color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "    color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "    # Test model\n",
    "    color_me_embed=np.expand_dims(color_me_embed,axis=0)\n",
    "    output = model(tf.convert_to_tensor(color_me,dtype=tf.float32), tf.convert_to_tensor(color_me_embed,dtype=tf.float32))\n",
    "    output = output * 128\n",
    "\n",
    "    # Output colorizations:\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[0][:,:,0]\n",
    "    cur[:,:,1:] = output[0]\n",
    "    imsave(\"result/img_0\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "num_epochs = 1000\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    image_gen, (tf.float32, tf.float32, tf.float32))\n",
    "value = ds.batch(20)\n",
    "checkpoint = tfe.Checkpoint(model=model)\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(\"./model\"))\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    i=0\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    for x,x1,y in value:\n",
    "        #20 batches in one epoch\n",
    "        if i==20:\n",
    "            break\n",
    "        grads = grad(model,x,x1, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                              global_step=tf.train.get_or_create_global_step())\n",
    "        i+=1\n",
    "        epoch_loss_avg(loss(model, x,x1, y))  # add current batch loss\n",
    "   \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"epoch time \",elapsed)\n",
    "    if epoch%10==0:\n",
    "        start_time = timeit.default_timer()\n",
    "        test(model,epoch)\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        print(\"test time \",elapsed)\n",
    "    if(epoch%50==0):\n",
    "        checkpoint.save(os.path.join(\"./model\", \"ckpt\"))\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    print(\"Epoch {:03d}: Loss: {:.9f}\".format(epoch,epoch_loss_avg.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

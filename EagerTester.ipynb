{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "#from keras import backend as K\n",
    "import timeit\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ColorModel, self).__init__()\n",
    "        self.layer1 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', strides=2)\n",
    "        self.layer2 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same')\n",
    "        self.layer3 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same', strides=2)\n",
    "        self.layer4 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same')\n",
    "        self.layer5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same', strides=2)\n",
    "        self.layer6 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same')\n",
    "        self.layer7 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same')\n",
    "        self.layer8 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same')\n",
    "        self.layer9 = tf.keras.layers.RepeatVector(32 * 32)\n",
    "        self.layer10 = tf.keras.layers.Reshape(([32, 32, 1536]))\n",
    "#        layer11 = concatenate([encoder_output, fusion_output], axis=3) \n",
    "        self.layer12 = tf.keras.layers.Conv2D(256, (1, 1), activation='relu', padding='same')\n",
    "\n",
    "        #Decoder\n",
    "        self.layer13 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same')\n",
    "        self.layer14 = tf.keras.layers.UpSampling2D((2, 2))\n",
    "        self.layer15 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same')\n",
    "        self.layer16 = tf.keras.layers.UpSampling2D((2, 2))\n",
    "        self.layer17 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same')\n",
    "        self.layer18 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same')\n",
    "        self.layer19 = tf.keras.layers.Conv2D(2, (3, 3), activation='tanh', padding='same')\n",
    "        self.layer20 = tf.keras.layers.UpSampling2D((2, 2))\n",
    "        \n",
    "    def call(self, input1,input2):\n",
    "        \"\"\"Run the model.\"\"\"\n",
    "        result = self.layer1(input1)\n",
    "        result = self.layer2(result)\n",
    "        result = self.layer3(result)\n",
    "        result = self.layer4(result)\n",
    "        result = self.layer5(result)\n",
    "        result = self.layer6(result)\n",
    "        result = self.layer7(result)\n",
    "        result = self.layer8(result)\n",
    "        result1=self.layer9(input2)\n",
    "        result1=self.layer10(result1)\n",
    "        result=tf.keras.layers.concatenate([result,result1])\n",
    "\n",
    "        result = self.layer12(result)\n",
    "        result = self.layer13(result)\n",
    "        result = self.layer14(result)\n",
    "        result = self.layer15(result)\n",
    "        result = self.layer16(result)\n",
    "        result = self.layer17(result)\n",
    "        result = self.layer18(result)\n",
    "        result = self.layer19(result)\n",
    "        result = self.layer20(result)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ColorModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"Train/\"\n",
    "folders=os.listdir(train_path)\n",
    "files=[]\n",
    "for f in folders:\n",
    "    files.extend([train_path+f+\"/\"+each for each in os.listdir(train_path+f)])\n",
    "random.shuffle(files)\n",
    "\n",
    "val=files[-100:]\n",
    "files=files[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x,x1, y):\n",
    "    y_ = model(x,x1)\n",
    "    return tf.losses.mean_squared_error(labels=y, predictions=y_)\n",
    "\n",
    "\n",
    "def grad(model, inputs,embed, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs,embed, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=np.load(\"test.npy\")\n",
    "names=np.load('test1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_gen():\n",
    "    global files\n",
    "    i=0\n",
    "    while True:\n",
    "        if(i>len(files) or i+1>len(files)):\n",
    "            i=0\n",
    "        x,x1,y=read_images(files[i:i+1])\n",
    "        x=x[0]\n",
    "        x1=x1[0]\n",
    "        y=y[0]\n",
    "        i+=1\n",
    "        yield x,x1,y\n",
    "        \n",
    "def read_images(files):\n",
    "    X = []\n",
    "    embed = []\n",
    "    for filename in files:\n",
    "        X.append(img_to_array(load_img(filename)))\n",
    "        embed.append(embeddings[np.argwhere(names == filename)[0][0]])\n",
    "\n",
    "    embed = np.array(embed, dtype=float)\n",
    "    X = np.array(X, dtype=float)/255\n",
    "    grayscaled_rgb = gray2rgb(rgb2gray(X))\n",
    "    lab_batch = rgb2lab(X)\n",
    "    X_batch = lab_batch[:,:,:,0]\n",
    "    X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "    Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "    return (X_batch,embed, Y_batch)\n",
    "\n",
    "val_x,val_x1,val_y = read_images(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,i):\n",
    "    color_me = []\n",
    "    color_me.append(img_to_array(load_img(files[0])))\n",
    "    color_me = np.array(color_me, dtype=float)\n",
    "    gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
    "    color_me_embed =embeddings[np.argwhere(names == files[0])[0][0]]\n",
    "    color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "    color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "    # Test model\n",
    "    color_me_embed=np.expand_dims(color_me_embed,axis=0)\n",
    "    output = model(tf.convert_to_tensor(color_me,dtype=tf.float32), tf.convert_to_tensor(color_me_embed,dtype=tf.float32))\n",
    "    output = output * 128\n",
    "\n",
    "    # Output colorizations:\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[0][:,:,0]\n",
    "    cur[:,:,1:] = output[0]\n",
    "    imsave(\"result/img_0\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time  28.80893547499727\n",
      "test time  0.11766852899745572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:130: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.002505680\n",
      "epoch time  28.10058647299593\n",
      "Epoch 001: Loss: 0.002500428\n",
      "epoch time  28.034092877001967\n",
      "Epoch 002: Loss: 0.002498059\n",
      "epoch time  28.089152532993467\n",
      "Epoch 003: Loss: 0.002496596\n",
      "epoch time  28.433253272\n",
      "Epoch 004: Loss: 0.002495537\n",
      "epoch time  28.07846629100095\n",
      "Epoch 005: Loss: 0.002494689\n",
      "epoch time  28.11818461600342\n",
      "Epoch 006: Loss: 0.002493967\n",
      "epoch time  28.08062624100421\n",
      "Epoch 007: Loss: 0.002493328\n",
      "epoch time  28.136538174003363\n",
      "Epoch 008: Loss: 0.002492739\n",
      "epoch time  28.0965453809913\n",
      "Epoch 009: Loss: 0.002492189\n",
      "epoch time  28.14839293299883\n",
      "test time  0.11805944399384316\n",
      "Epoch 010: Loss: 0.002491673\n",
      "epoch time  28.431979091998073\n",
      "Epoch 011: Loss: 0.002491176\n",
      "epoch time  28.138254727004096\n",
      "Epoch 012: Loss: 0.002490698\n",
      "epoch time  29.241184621991124\n",
      "Epoch 013: Loss: 0.002490240\n",
      "epoch time  28.601219421994756\n",
      "Epoch 014: Loss: 0.002489791\n",
      "epoch time  28.09032566600945\n",
      "Epoch 015: Loss: 0.002489354\n",
      "epoch time  28.116758763993857\n",
      "Epoch 016: Loss: 0.002488925\n",
      "epoch time  28.505712486003176\n",
      "Epoch 017: Loss: 0.002488503\n",
      "epoch time  28.103983159002382\n",
      "Epoch 018: Loss: 0.002488091\n",
      "epoch time  28.09011619199009\n",
      "Epoch 019: Loss: 0.002487687\n",
      "epoch time  28.074750755011337\n",
      "test time  0.11766326799988747\n",
      "Epoch 020: Loss: 0.002487289\n",
      "epoch time  28.27415729900531\n",
      "Epoch 021: Loss: 0.002486900\n",
      "epoch time  28.182419574994128\n",
      "Epoch 022: Loss: 0.002486516\n",
      "epoch time  28.135127243003808\n",
      "Epoch 023: Loss: 0.002486137\n",
      "epoch time  28.16799108601117\n",
      "Epoch 024: Loss: 0.002485762\n",
      "epoch time  28.67135362699628\n",
      "Epoch 025: Loss: 0.002485394\n",
      "epoch time  28.060799126003985\n",
      "Epoch 026: Loss: 0.002485030\n",
      "epoch time  28.09181732799334\n",
      "Epoch 027: Loss: 0.002484669\n",
      "epoch time  28.06517628300935\n",
      "Epoch 028: Loss: 0.002484313\n",
      "epoch time  28.671777247000136\n",
      "Epoch 029: Loss: 0.002483961\n",
      "epoch time  28.245057260006433\n",
      "test time  0.11863755900412798\n",
      "Epoch 030: Loss: 0.002483610\n",
      "epoch time  28.267224149996764\n",
      "Epoch 031: Loss: 0.002483261\n",
      "epoch time  28.159975558010046\n",
      "Epoch 032: Loss: 0.002482917\n",
      "epoch time  28.089790551995975\n",
      "Epoch 033: Loss: 0.002482575\n",
      "epoch time  28.562462337999023\n",
      "Epoch 034: Loss: 0.002482234\n",
      "epoch time  28.126724506000755\n",
      "Epoch 035: Loss: 0.002481897\n",
      "epoch time  28.227001360995928\n",
      "Epoch 036: Loss: 0.002481558\n",
      "epoch time  31.65564091199485\n",
      "Epoch 037: Loss: 0.002481225\n",
      "epoch time  30.3020260919875\n",
      "Epoch 038: Loss: 0.002480893\n",
      "epoch time  29.89844245898712\n",
      "Epoch 039: Loss: 0.002480563\n",
      "epoch time  28.790903578003054\n",
      "test time  0.11966171899985056\n",
      "Epoch 040: Loss: 0.002480236\n",
      "epoch time  28.758465837992844\n",
      "Epoch 041: Loss: 0.002479908\n",
      "epoch time  28.95784456700494\n",
      "Epoch 042: Loss: 0.002479585\n",
      "epoch time  28.798294919994078\n",
      "Epoch 043: Loss: 0.002479263\n",
      "epoch time  28.70749594499648\n",
      "Epoch 044: Loss: 0.002478943\n",
      "epoch time  28.802439081991906\n",
      "Epoch 045: Loss: 0.002478625\n",
      "epoch time  28.76554978999775\n",
      "Epoch 046: Loss: 0.002478307\n",
      "epoch time  28.804980788001558\n",
      "Epoch 047: Loss: 0.002477992\n",
      "epoch time  28.76231310000003\n",
      "Epoch 048: Loss: 0.002477677\n",
      "epoch time  28.83872108599462\n",
      "Epoch 049: Loss: 0.002477364\n",
      "epoch time  29.29005346800841\n",
      "test time  0.12149198600673117\n",
      "Epoch 050: Loss: 0.002477054\n",
      "epoch time  28.827485347006586\n",
      "Epoch 051: Loss: 0.002476746\n",
      "epoch time  28.875779965994298\n",
      "Epoch 052: Loss: 0.002476436\n",
      "epoch time  28.864433988012024\n",
      "Epoch 053: Loss: 0.002476130\n",
      "epoch time  28.93951124700834\n",
      "Epoch 054: Loss: 0.002475823\n",
      "epoch time  28.772794407996116\n",
      "Epoch 055: Loss: 0.002475519\n",
      "epoch time  28.825275541006704\n",
      "Epoch 056: Loss: 0.002475215\n",
      "epoch time  28.82296831799613\n",
      "Epoch 057: Loss: 0.002474913\n",
      "epoch time  29.180966133004404\n",
      "Epoch 058: Loss: 0.002474613\n",
      "epoch time  28.78493762400467\n",
      "Epoch 059: Loss: 0.002474313\n",
      "epoch time  28.81887184700463\n",
      "test time  0.12343934099772014\n",
      "Epoch 060: Loss: 0.002474014\n",
      "epoch time  28.882782176995534\n",
      "Epoch 061: Loss: 0.002473716\n",
      "epoch time  28.829410873993766\n",
      "Epoch 062: Loss: 0.002473419\n",
      "epoch time  29.216230528007145\n",
      "Epoch 063: Loss: 0.002473123\n",
      "epoch time  28.820938332006335\n",
      "Epoch 064: Loss: 0.002472828\n",
      "epoch time  28.831323206002708\n",
      "Epoch 065: Loss: 0.002472535\n",
      "epoch time  28.800253578010597\n",
      "Epoch 066: Loss: 0.002472242\n",
      "epoch time  29.2058443089918\n",
      "Epoch 067: Loss: 0.002471950\n",
      "epoch time  28.820001104002586\n",
      "Epoch 068: Loss: 0.002471659\n",
      "epoch time  28.82708030800859\n",
      "Epoch 069: Loss: 0.002471369\n",
      "epoch time  28.759640099000535\n",
      "test time  0.12009591000969522\n",
      "Epoch 070: Loss: 0.002471079\n",
      "epoch time  29.445641603000695\n",
      "Epoch 071: Loss: 0.002470791\n",
      "epoch time  28.4916519279941\n",
      "Epoch 072: Loss: 0.002470502\n",
      "epoch time  28.31011116699665\n",
      "Epoch 073: Loss: 0.002470216\n",
      "epoch time  28.79494094698748\n",
      "Epoch 074: Loss: 0.002469929\n",
      "epoch time  29.1031543029967\n",
      "Epoch 075: Loss: 0.002469643\n",
      "epoch time  28.81782103399746\n",
      "Epoch 076: Loss: 0.002469359\n",
      "epoch time  28.81967204900866\n",
      "Epoch 077: Loss: 0.002469074\n",
      "epoch time  28.88952536600118\n",
      "Epoch 078: Loss: 0.002468791\n",
      "epoch time  29.135264647004078\n",
      "Epoch 079: Loss: 0.002468507\n",
      "epoch time  28.781419876002474\n",
      "test time  0.12395583299803548\n",
      "Epoch 080: Loss: 0.002468225\n",
      "epoch time  28.842853404989\n",
      "Epoch 081: Loss: 0.002467943\n",
      "epoch time  28.801954763010144\n",
      "Epoch 082: Loss: 0.002467662\n",
      "epoch time  29.127567492992966\n",
      "Epoch 083: Loss: 0.002467382\n",
      "epoch time  28.82555811399652\n",
      "Epoch 084: Loss: 0.002467103\n",
      "epoch time  28.779460938996635\n",
      "Epoch 085: Loss: 0.002466824\n",
      "epoch time  28.788142449993757\n",
      "Epoch 086: Loss: 0.002466547\n",
      "epoch time  29.195670614004484\n",
      "Epoch 087: Loss: 0.002466269\n",
      "epoch time  28.832178411001223\n",
      "Epoch 088: Loss: 0.002465992\n",
      "epoch time  28.593395703996066\n",
      "Epoch 089: Loss: 0.002465715\n",
      "epoch time  28.8284419089905\n",
      "test time  0.12087113699817564\n",
      "Epoch 090: Loss: 0.002465440\n",
      "epoch time  28.7454125360091\n",
      "Epoch 091: Loss: 0.002465165\n",
      "epoch time  29.455462866011658\n",
      "Epoch 092: Loss: 0.002464891\n",
      "epoch time  29.27050736300589\n",
      "Epoch 093: Loss: 0.002464616\n",
      "epoch time  28.190800323005533\n",
      "Epoch 094: Loss: 0.002464343\n",
      "epoch time  28.20843089900154\n",
      "Epoch 095: Loss: 0.002464071\n",
      "epoch time  28.551493001999916\n",
      "Epoch 096: Loss: 0.002463799\n",
      "epoch time  28.136883843006217\n",
      "Epoch 097: Loss: 0.002463527\n",
      "epoch time  28.201460512005724\n",
      "Epoch 098: Loss: 0.002463256\n",
      "epoch time  28.173204661012278\n",
      "Epoch 099: Loss: 0.002462986\n"
     ]
    }
   ],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "#gen=image_gen(20)\n",
    "num_epochs = 100\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "    image_gen, (tf.float32, tf.float32, tf.float32))\n",
    "value = ds.batch(20)\n",
    "checkpoint = tfe.Checkpoint(model=model)\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(\"./model\"))\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    #epoch_accuracy = tfe.metrics.Accuracy()\n",
    "    i=0\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "# code you want to evaluate\n",
    "    for x,x1,y in value:\n",
    "    # Optimize the model\n",
    "        if i==20:\n",
    "            break\n",
    "        grads = grad(model,x,x1, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                              global_step=tf.train.get_or_create_global_step())\n",
    "        i+=1\n",
    "        epoch_loss_avg(loss(model, x,x1, y))  # add current batch loss\n",
    "   \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"epoch time \",elapsed)\n",
    "    if epoch%10==0:\n",
    "        start_time = timeit.default_timer()\n",
    "        test(model,epoch)\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        print(\"test time \",elapsed)\n",
    "    if(epoch%10==0):\n",
    "        checkpoint.save(os.path.join(\"./model\", \"ckpt\"))\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    #train_accuracy_results.append(epoch_accuracy.result())\n",
    "    print(\"Epoch {:03d}: Loss: {:.9f}\".format(epoch,epoch_loss_avg.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
